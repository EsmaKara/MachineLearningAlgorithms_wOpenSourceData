# HepsiEmlak ML Pipeline

Data cleaning and machine learning experiments on Turkish real estate listings collected from **HepsiEmlak**.  
This project was developed by a **10-person team** with a strong emphasis on **data preprocessing**, feature engineering, and predictive modeling for property type and price estimation.

Contributors: Esma Kara, Dilara Top, Hayrunnisa YÄ±lmaz, Esra Ã–zden
---

## ğŸ“Š Project Overview
- **Dataset size:** 2,180 rows Ã— 135 columns  
- **Final cleaned dataset:** 57 columns (up to **87 features** after encoding)  
- **Teamwork:** Each member worked on a subset of columns, with weekly meetings for sharing insights and aligning methodologies.  
- **Main focus:** Data preparation, feature engineering, and applying multiple ML models for classification and regression tasks.  

---

## ğŸ§¹ Data Preparation
The most time-consuming and critical phase of the project was **data cleaning**. Steps included:

- **Column elimination:**  
  - Removed columns with >95% missing values  
  - Removed columns containing only `0`/`1`  
  - Removed columns with a single constant string value  

- **Distributed feature analysis:**  
  Each member handled ~7 columns to ensure thorough cleaning and preprocessing.  

- **Data cleaning & transformation:**  
  - Filled missing values using:
    - Information extracted from the `description` field  
    - Derived values from correlated columns  
    - Custom prediction functions for specific attributes  
  - Split multi-valued columns into multiple features  
  - Extracted meaningful data from HTML tags  
  - Created new engineered features, e.g.:
    - Distance to city center  
    - Distance to sea  
    - Numerical floor ranking system  
  - Corrected contradictory or incorrect entries  
  - Outlier detection and adjustments  

- **Encoding:**  
  Since most ML algorithms require numerical input, categorical variables were encoded, raising the total number of features to **87**.  

- **Overfitting prevention:**  
  Columns that led to overfitting during model training were **excluded from the final feature set** to improve generalization.  

---

## ğŸ¤– Modeling Scenarios
We implemented ML models in **three main scenarios**:

1. **Property Type Prediction (Classification)**  
   - Algorithms: Random Forest, Logistic Regression  
   - Techniques: SMOTE, GridSearchCV, SelectKBest, PCA, Cross-Validation  
   - Evaluation: Performance metrics & learning curves  

2. **Price Prediction â€“ Categorical (Classification by price ranges)**  
   - Algorithms: Random Forest, XGBoost, LightGBM, Decision Tree  
   - Techniques: GridSearchCV, RandomizedSearchCV  
   - Evaluation: Metrics & learning curves  

3. **Price Prediction â€“ Numerical (Regression)**  
   - Algorithms: Linear Regression, CART, Random Forest, LightGBM  
   - Techniques: Feature Selection (SelectKBest, RFE), Correlation Analysis, Log Transformation, GridSearchCV, RandomizedSearchCV, Cross-Validation  
   - Evaluation: Metrics & learning curves  

---

## ğŸ› ï¸ Technologies Used
- **Languages & Libraries:** Python, Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn, XGBoost, LightGBM  
- **Collaboration:** Version control & teamwork (10 members)  
- **Approach:** Iterative cleaning, feature engineering, and ML experiments  

---

# What we are asked for?
[Veri MadenciliÄŸi DÃ¶nem Proje Ä°sterleri.docx](https://github.com/user-attachments/files/22122002/Veri.Madenciligi.Donem.Proje.Isterleri.docx) (in Turkish)

## Project Report 
[Rapor.docx](https://github.com/user-attachments/files/22122039/Rapor.docx) (in Turkish)



---

## ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e Versiyon

# HepsiEmlak ML Pipeline

**HepsiEmlak** Ã¼zerinden toplanan TÃ¼rkÃ§e emlak ilanlarÄ± Ã¼zerinde veri temizleme ve makine Ã¶ÄŸrenmesi Ã§alÄ±ÅŸmalarÄ±.  
Bu proje, **10 kiÅŸilik bir ekip** tarafÄ±ndan geliÅŸtirilmiÅŸ olup, Ã¶zellikle **veri Ã¶n iÅŸleme**, Ã¶zellik mÃ¼hendisliÄŸi ve konut tipi ile fiyat tahmini iÃ§in makine Ã¶ÄŸrenmesi modellerine odaklanmaktadÄ±r.

---

## ğŸ“Š Proje Ã–zeti
- **Veri seti boyutu:** 2.180 satÄ±r Ã— 135 sÃ¼tun  
- **TemizlenmiÅŸ nihai veri seti:** 57 sÃ¼tun (**encoding sonrasÄ± 87 Ã¶zellik**)  
- **Ekip Ã§alÄ±ÅŸmasÄ±:** Her Ã¼ye belirli sÃ¼tunlarÄ± Ã¼stlenerek Ã¼zerinde Ã§alÄ±ÅŸtÄ±, haftalÄ±k toplantÄ±lar ile fikir paylaÅŸÄ±mÄ± ve yÃ¶ntem birliÄŸi saÄŸlandÄ±.  
- **Ana odak:** Veri hazÄ±rlÄ±ÄŸÄ±, Ã¶zellik mÃ¼hendisliÄŸi ve sÄ±nÄ±flandÄ±rma/regresyon gÃ¶revleri iÃ§in ML modellerinin uygulanmasÄ±.  

---

## ğŸ§¹ Veri HazÄ±rlama
Projenin en zaman alÄ±cÄ± ve kritik aÅŸamasÄ± **veri temizleme** olmuÅŸtur. AdÄ±mlar ÅŸunlardÄ±r:

- **SÃ¼tun elemesi:**  
  - %95â€™ten fazla eksik deÄŸer iÃ§eren sÃ¼tunlar kaldÄ±rÄ±ldÄ±  
  - Sadece `0` veya `1` deÄŸerinden oluÅŸan sÃ¼tunlar kaldÄ±rÄ±ldÄ±  
  - Sadece tek bir sabit string deÄŸeri iÃ§eren sÃ¼tunlar kaldÄ±rÄ±ldÄ±  

- **DaÄŸÄ±tÄ±lmÄ±ÅŸ Ã¶zellik analizi:**  
  Her ekip Ã¼yesi yaklaÅŸÄ±k 7 sÃ¼tun Ã¼zerinde Ã§alÄ±ÅŸarak detaylÄ± temizlik yaptÄ±.  

- **Veri temizleme & dÃ¶nÃ¼ÅŸtÃ¼rme:**  
  - Eksik veriler dolduruldu:\n    - `description` sÃ¼tunundan Ã§Ä±karÄ±lan bilgilerle  \n    - Ä°liÅŸkili sÃ¼tunlardan elde edilen verilerle  \n    - Ã–zel tahmin fonksiyonlarÄ± kullanÄ±larak  \n  - Birden fazla veri iÃ§eren sÃ¼tunlar ayrÄ±larak yeni sÃ¼tunlar oluÅŸturuldu  
  - HTML tagâ€™leri iÃ§erisindeki faydalÄ± veriler Ã§Ä±karÄ±ldÄ±  
  - Yeni Ã¶zellikler oluÅŸturuldu, Ã¶rn.:\n    - Merkeze uzaklÄ±k  \n    - Denize uzaklÄ±k  \n    - Kat bilgisi sayÄ±sal derecelendirme  \n  - Ã‡eliÅŸkili ve hatalÄ± bilgiler dÃ¼zeltildi  
  - AykÄ±rÄ± deÄŸerler tespit edilerek dÃ¼zenlendi  

- **Encoding:**  
  Ã‡oÄŸu ML algoritmasÄ± sayÄ±sal veri gerektirdiÄŸinden kategorik deÄŸiÅŸkenler encode edilerek toplam Ã¶zellik sayÄ±sÄ± **87â€™ye** Ã§Ä±ktÄ±.  

- **Overfitting Ã¶nleme:**  
  Model eÄŸitiminde aÅŸÄ±rÄ± uyuma yol aÃ§an sÃ¼tunlar **kullanÄ±lmayarak** genelleme baÅŸarÄ±sÄ± artÄ±rÄ±ldÄ±.  

---

## ğŸ¤– Modelleme SenaryolarÄ±
Projede **Ã¼Ã§ temel senaryo** uygulanmÄ±ÅŸtÄ±r:

1. **Konut Tipi Tahmini (SÄ±nÄ±flandÄ±rma)**  
   - Algoritmalar: Random Forest, Lojistik Regresyon  
   - Teknikler: SMOTE, GridSearchCV, SelectKBest, PCA, Cross-Validation  
   - DeÄŸerlendirme: Performans metrikleri & Ã¶ÄŸrenme eÄŸrileri  

2. **Fiyat Tahmini â€“ Kategorik (Fiyat aralÄ±klarÄ±na gÃ¶re sÄ±nÄ±flandÄ±rma)**  
   - Algoritmalar: Random Forest, XGBoost, LightGBM, Decision Tree  
   - Teknikler: GridSearchCV, RandomizedSearchCV  
   - DeÄŸerlendirme: Metrikler & Ã¶ÄŸrenme eÄŸrileri  

3. **Fiyat Tahmini â€“ SayÄ±sal (Regresyon)**  
   - Algoritmalar: Linear Regression, CART, Random Forest, LightGBM  
   - Teknikler: Ã–zellik seÃ§imi (SelectKBest, RFE), Korelasyon Analizi, Logaritmik DÃ¶nÃ¼ÅŸÃ¼m, GridSearchCV, RandomizedSearchCV, Cross-Validation  
   - DeÄŸerlendirme: Metrikler & Ã¶ÄŸrenme eÄŸrileri  

---

## ğŸ› ï¸ KullanÄ±lan Teknolojiler
- **Diller & KÃ¼tÃ¼phaneler:** Python, Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn, XGBoost, LightGBM  
- **Ekip Ã§alÄ±ÅŸmasÄ±:** Versiyon kontrolÃ¼ & ortak Ã§alÄ±ÅŸma (10 kiÅŸi)  
- **YaklaÅŸÄ±m:** TekrarlamalÄ± temizlik, Ã¶zellik mÃ¼hendisliÄŸi ve ML deneyleri  
